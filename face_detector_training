import pandas as pd
import numpy as np
import os
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import EarlyStopping


# Ścieżka do folderu ze zdjęciami
image_folder = 'sad v1'

# Funkcja do ładowania i przetwarzania obrazu
def load_and_preprocess_image(row, image_folder):
    image_path = os.path.join(image_folder, row['image_name'])
    image = load_img(image_path, target_size=(224, 224))
    image = img_to_array(image) / 255.0  # Uproszczona normalizacja

    scale_x = 224 / row['image_width']
    scale_y = 224 / row['image_height']

    x_min = row['bbox_x'] * scale_x
    y_min = row['bbox_y'] * scale_y
    x_max = (row['bbox_x'] + row['bbox_width']) * scale_x
    y_max = (row['bbox_y'] + row['bbox_height']) * scale_y

    bbox = np.array([x_min, y_min, x_max, y_max]) / 224.0  # Normalizacja bounding boxów
    return image, bbox

# Załadowanie danych
data = pd.read_csv('filesss/labels_my-project-name_2024-07-18-11-13-19.csv')

# Filtrowanie wierszy, aby zachować tylko te, które mają 'label_name' równy 'head'
data = data[data['label_name'] == 'head']

X = []
y = []

for index, row in data.iterrows():
    image, bbox = load_and_preprocess_image(row, image_folder)
    X.append(image)
    y.append(bbox)

X = np.array(X)
y = np.array(y)

# Konfiguracja modelu bazowego
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = Flatten()(x)
x = Dense(1024, activation='relu')(x)
x = Dense(512, activation='relu')(x)
predictions = Dense(4, activation='linear')(x)  # x_min, y_min, x_max, y_max

model = Model(inputs=base_model.input, outputs=predictions)

# Zamrożenie warstw bazowego modelu
for layer in base_model.layers:
    layer.trainable = False

# Kompilacja modelu
model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')



# Wczesne zatrzymanie
early_stopping = EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True)

# Trenowanie modelu z wczesnym zatrzymaniem
model.fit(X, y, epochs=100, batch_size=64, validation_split=0.1, callbacks=[early_stopping])

# Zapisanie modelu
model.save('dog_face_detector.h5')

# Funkcja do przewidywania bounding boxów
def predict_bounding_box(model, image_path):
    image = load_img(image_path, target_size=(224, 224))
    image = img_to_array(image)
    image = image / 255.0
    image = np.expand_dims(image, axis=0)
    bbox = model.predict(image)[0]
    bbox = bbox * 224  # Denormalizacja
    return bbox

# Załadowanie wytrenowanego modelu
model = tf.keras.models.load_model('dog_face_detector.h5')

# Przykładowe użycie modelu do przewidywania bounding boxu na nowym obrazie
new_image_path = os.path.join(image_folder, '5444895_72b1d76feb_b.jpg')
bbox = predict_bounding_box(model, new_image_path)
print(f'Bounding box coordinates: {bbox}')

# Funkcja do wyświetlania obrazu z bounding boxem
def display_image_with_bbox(image_path, bbox):
    image = load_img(image_path, target_size=(224, 224))
    image = img_to_array(image)
    image = image / 255.0

    fig, ax = plt.subplots(1)
    ax.imshow(image)

    # Dodanie prostokąta bounding box
    rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2]-bbox[0], bbox[3]-bbox[1], linewidth=2, edgecolor='r', facecolor='none')
    ax.add_patch(rect)

    plt.show()

image_names = ['97968156_85f06a11c5_b.jpg', '100190413_08af1e0b78_b.jpg']

for image_name in image_names:
    new_image_path = os.path.join(image_folder, image_name)
    bbox = predict_bounding_box(model, new_image_path)
    print(f'Bounding box coordinates for {image_name}: {bbox}')
    display_image_with_bbox(new_image_path, bbox)


# Tworzenie czarnego obrazu 224x224
black_image = np.zeros((224, 224, 3))

# Funkcja do przewidywania bounding boxów dla czarnego obrazu
def predict_bounding_box_for_black_image(model):
    black_image_expanded = np.expand_dims(black_image, axis=0)
    bbox = model.predict(black_image_expanded)[0]
    bbox = bbox * 224  # Denormalizacja
    return bbox

# Przewidywanie bounding boxu dla czarnego obrazu
bbox_black_image = predict_bounding_box_for_black_image(model)
print(f'Bounding box coordinates for black image: {bbox_black_image}')

# Wyświetlanie czarnego obrazu z bounding boxem
def display_black_image_with_bbox(black_image, bbox):
    fig, ax = plt.subplots(1)
    ax.imshow(black_image)

    # Dodanie prostokąta bounding box
    rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2]-bbox[0], bbox[3]-bbox[1], linewidth=2, edgecolor='r', facecolor='none')
    ax.add_patch(rect)

    plt.show()

display_black_image_with_bbox(black_image, bbox_black_image)
