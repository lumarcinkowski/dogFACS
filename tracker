import cv2
from ultralytics import YOLO
import numpy as np
import random

# Load the pre-trained YOLOv8 model for dog detection
model_path = 'C:\\Users\\Andrzej\\Downloads\\yolov8_dogface_dataset2_80epochs_best.pt'
dog_model = YOLO(model_path)

# Path to your video file
video_path = 'C:\\Users\\Andrzej\\Downloads\\gucio.mp4'

# Open the video file
cap = cv2.VideoCapture(video_path)

# Check if the video opened successfully
if not cap.isOpened():
    print("Error: Could not open video.")
    exit()

# Define video writer to save the output video
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
out = cv2.VideoWriter('dwa_psy.mp4', fourcc, 30.0, (frame_width, frame_height))

# Initialize variables for tracking
trackers = []  # List to hold multiple trackers
frame_count = 0
detection_interval = 30 # Re-detect every 15 frames

while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame_count += 1

    # Perform dog detection every 'detection_interval' frames or when trackers list is empty
    if frame_count % detection_interval == 0 or not trackers:
        trackers.clear()

        # Perform dog detection
        dog_results = dog_model(frame)

        for result in dog_results:
            for box in result.boxes:
                if box.cls == 0:  # Assuming class 0 corresponds to dogs
                    confidence = box.conf[0]  # Extract confidence score

                    # Only consider detections with confidence > 0.7
                    if confidence > 0.6:
                        # Extract the coordinates of the bounding box for the dog
                        x1, y1, x2, y2 = map(int, box.xyxy[0])

                        # Initialize a new tracker for the detected dog
                        tracker = cv2.TrackerCSRT_create()
                        #tracker = cv2.TrackerMedianFlow_create()
                        #tracker = cv2.TrackerKCF_create()
                        tracker.init(frame, (x1, y1, x2 - x1, y2 - y1))

                        # Generate a random color for this dog (BGR format)
                        dog_color = tuple(np.random.randint(0, 255, size=3).tolist())

                        # Add the tracker, its color, and confidence to the list
                        trackers.append((tracker, dog_color, confidence))

    # Update each tracker and draw the bounding box
    for tracker, color, confidence in trackers:
        success, bbox = tracker.update(frame)
        if success:
            x1, y1, w, h = map(int, bbox)
            x2, y2 = x1 + w, y1 + h
            # Draw rectangle with the assigned color
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            # Display the confidence score
            cv2.putText(frame, f'{confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        else:
            trackers.remove((tracker, color, confidence))  # Remove tracker if it fails

    # Write the processed frame to the output video
    out.write(frame)

    # Display the frame (optional)
    cv2.imshow('Frame', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release video objects
cap.release()
out.release()
cv2.destroyAllWindows()
