import cv2
from ultralytics import YOLO
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np
import os
from google.colab.patches import cv2_imshow

# Załaduj model YOLOv8 nano
yolo_model = YOLO('yolov8n.pt')  # Użyj odpowiedniego pliku wagi

# Załaduj model do detekcji twarzy psów
dog_face_model = load_model('/content/drive/MyDrive/dog_face_detector.h5')

# Funkcja do detekcji twarzy psa
def detect_dog_face(image, bbox):
    x_min, y_min, x_max, y_max = map(int, bbox)
    dog_face_region = image[y_min:y_max, x_min:x_max]
    if dog_face_region.size == 0:
        return None  # Brak wykrycia twarzy psa

    dog_face_region_resized = cv2.resize(dog_face_region, (224, 224))
    dog_face_array = img_to_array(dog_face_region_resized) / 255.0
    dog_face_array = np.expand_dims(dog_face_array, axis=0)

    face_bbox = dog_face_model.predict(dog_face_array)[0] * [x_max-x_min, y_max-y_min, x_max-x_min, y_max-y_min]
    face_bbox = face_bbox + [x_min, y_min, x_min, y_min]
    return face_bbox

# Funkcja do przetwarzania i wykrywania obiektów w klatkach wideo
def detect_objects(frame):
    results = yolo_model(frame)
    for result in results:
        boxes = result.boxes
        for box in boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = box.conf[0]
            cls = int(box.cls[0])
            label = yolo_model.names[cls]
            if label == "dog":
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, f'{label} {confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

                face_bbox = detect_dog_face(frame, (x1, y1, x2, y2))
                if face_bbox is not None:
                    fx1, fy1, fx2, fy2 = map(int, face_bbox)
                    cv2.rectangle(frame, (fx1, fy1), (fx2, fy2), (255, 0, 0), 2)
                    cv2.putText(frame, 'dog face', (fx1, fy1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
    return frame

# Przetwarzanie wideo i zapis przetworzonych klatek do nowego pliku wideo
input_path = '/content/test.mp4'  # Podaj ścieżkę do swojego pliku wideo
output_path = '2output_video.mp4'
cap = cv2.VideoCapture(input_path)
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    processed_frame = detect_objects(frame)
    out.write(processed_frame)

cap.release()
out.release()
cv2.destroyAllWindows()

print("Przetwarzanie zakończone i zapisano wideo jako 'output_video.mp4'")
